[TOC]

# 高级篇 - 分布式缓存 Redis集群

# 0、单节点Redis的问题

* **数据丢失问题**：

  Redis是内存存储，服务重启可能会丢失数据

  解决方案：利用Redis数据持久化，将数据写入磁盘

* **并发能力问题**：

  单节点Redis并发能力虽然不错，单也无法满足如618这样的高并发场景

  解决方案：搭建主从集群，实现读写分离

* **故障恢复问题**：

  如果Redis宕机，则服务不可用，需要一种自动的故障恢复手段

  解决方案：利用Redis哨兵，实现健康检测和自动恢复

* **存储能力问题**：

  Redis基于内存，单节点能存储的数据量难以满足海量数据需求

  解决方案：搭建分片集群，利用插槽机制实现动态扩容



# 一、Redis持久化

Redis有两种持久化，分别是RDB持久化与AOF持久化

## 1.1 RDB 持久化

### 1.1.1 基本介绍

RDB全称Redis Database Backup file (**Redis数据备份文件**)，也被叫做**Redis数据快照**。

**简单来说就是把内存中的所有数据都记录到磁盘中**。（保存在了当前目录）当Redis实例故障重启后，从磁盘读取快照文件，恢复数据

> 快照文件称为RBD文件，默认保存在当前运行目录
>
> ![image-20230710095530365](https://picture-typora-zhangjingqi.oss-cn-beijing.aliyuncs.com/image-20230710095530365.png)

**Redis怎么执行一下RBD文件？**

* **第一种**

先使用下面命令连接Redis，然后再执行save命令，此时就会去执行RBD的备份操作了。

```
redis-cli
save
```

而这个执行的动作，是由Redis的主进程来完成的。而Redis是单线程，一旦执行了RDB，就不能执行其他动作了。

除此之外，RDB是把数据写入到磁盘，而磁盘IO往往是比较慢的，数据量比较大的话耗时比较久。

**这种情况适合在Redis停机之前使用**



> 如果是我们自己主动停机的时候，它会自动进行一次RDB。
>
> 也就是说默认就有持久化
>
> ![image-20230710101055739](https://picture-typora-zhangjingqi.oss-cn-beijing.aliyuncs.com/image-20230710101055739.png)



* **第二种**

连接客户端后执行bgsave命令。

这个保存的命令是在后台异步执行的，开启子进程执行RDB，避免主进程受到影响

```
redis-cli
bgsave
```

**这种情况适合在Redis运行时做**

****

**如果我们想周期备份怎么办？**

Redis内部有触发RDB机制，可以在redis.conf文件中找到，格式如下所示

![image-20230710102450223](https://picture-typora-zhangjingqi.oss-cn-beijing.aliyuncs.com/image-20230710102450223.png)

****

**RBD的其他配置也可以在redis.conf文件中设置**：

![image-20230710102716538](https://picture-typora-zhangjingqi.oss-cn-beijing.aliyuncs.com/image-20230710102716538.png)

> RDB文件保存在当前目录就是因为上图中的 dir./

****

### 1.1.2 RDB的fork原理

**bgsave开始时会fork主进程得到子进程，子进程共享主进程的内存数据**。

**完成fork后读取内存数据并写入RDB文件**。

> 因为是异步的，所以几乎可以做到对主进程零阻塞。
>
> 为什么是几乎？而不是完全？
>
> 因为读取内存数据写入RDB文件确实是异步执行的，但子进程的获取却不是，而是fork主进程得来的，而fork的过程是堵塞的，主线程只能做这个事，不能接收用户请求，因此我们必须加快fork的速度

****

**fork底层是怎么实现的呢？**

可以将物理内存理解为电脑中的内存条。Redis的主线程要实现对Redis的读写，也是在内存中操作。

在Linux系统中，所有的进程都没有办法直接操作物理内存，而是由操作系统给每个进程**分配一个虚拟内存**，主进程只能操作虚拟内存，而后操作系统会维护一个虚拟内存与物理内存之间的映射关系表，这个表称为页表

**所以：主进程操作虚拟内存，而虚拟内存基于页表的映射关系到我们的物理内存真正的存储位置，这样就实现对物理内存数据的读写**

![image-20230710104913687](https://picture-typora-zhangjingqi.oss-cn-beijing.aliyuncs.com/image-20230710104913687.png)

而我们fork的时候会创建一个子进程，他不是把内存中的数据做拷贝，仅仅是把页表做拷贝，当子进程有了和主进程一样的映射关系，子进程操作自己的虚拟内存时，会最终映射到相同的物理内存区域，这样**实现了主进程与子进程之间内存数据共享**，这样就无需拷贝内存中的数据，直接实现内存共享后速度就会变得非常的快，阻塞的时间就尽可能的缩短了

**此时子进程就能大胆的读取物理内存中的数据**了，把他写入磁盘当中的一个文件里面去。**并且新的RBD文件会替换旧的RDB文件**

**异步持久化就实现了**

![image-20230710105441541](https://picture-typora-zhangjingqi.oss-cn-beijing.aliyuncs.com/image-20230710105441541.png)



**子进程写RDB的过程中，主进程依然可以修改内存中的数据**

如果子进程读的时候主进程也正在写，此时读写之间可能会有冲突，甚至有可能会出现脏数据

**为了避免这种情况的发生，fork采用copy-on-write技术**

当我要去写的时候，我做一个拷贝，现在上图中是没有把数据做拷贝的，而是共享的，然后fork会**把这个共享内存标记为read-only只读模式**,任何一个进程都只能来读取数据而不能写数据

![image-20230710110108572](https://picture-typora-zhangjingqi.oss-cn-beijing.aliyuncs.com/image-20230710110108572.png)

**那如果主进程接下来写怎么办？**

他必须先拷贝一份数据（比如对数据B修改，就先拷贝一份数据B），再去完成写操作。并且之后主进程也在这个copy的数据里面读了，不再去read-only里面去了，也就是说主线程的页表映射关系发生了改变

![image-20230710110437986](https://picture-typora-zhangjingqi.oss-cn-beijing.aliyuncs.com/image-20230710110437986.png)

**但是！ 极端情况下，如果子进程写RDB文件的速度比较慢，并且主线程中有需求请求需要写入Redis，修改的数据也非常的多，也就是说要copy的数据也比较多，意味着Redis对于内存的占用要翻倍！**



### 1.2.3 总结

**RDB方式bgsave的基本流程**

* fork主进程得到一个子进程，共享内存空间
* 子进程读取内存数据写入新的RDB文件
* 用新RDB文件替换旧的RDB文件



**RDB会在什么时候执行？ save 60 1000代表什么含义？**

* 默认服务停止时
* 代表60秒内至少执行1000次修改则触发RDB



**RDB的缺点？**

* 安全漏洞问题。每隔60秒做一个持久化，但是60秒之间并没有做持久化，在这个过程当中产生的所有的写操作，一旦宕机就丢失。
* fork子进程、压缩、写出RDB文件都比较耗时





## 1.2 AOF持久化

**大大提高数据的安全性，弥补RDB的缺陷**

**AOF全**称为Append Only File (**追加文件**)。

**Redis处理的每一个写命令都会记录在AOF文件，可以看做是命令日志文件**

> 把Redis所有的写操作的命令记录到一个文件命令当中，这个文件中的内容是主键累加的过程
>

![image-20230710111738925](https://picture-typora-zhangjingqi.oss-cn-beijing.aliyuncs.com/image-20230710111738925.png)



如果将来Redis出现了问题，要恢复数据，就可以读取AOP文件，把里面的命令从到开始再执行一遍



**AOF默认是关闭的，需要修改redis.conf配置文件来开启AOF**

![image-20230710111928433](https://picture-typora-zhangjingqi.oss-cn-beijing.aliyuncs.com/image-20230710111928433.png)



**AOF的命令记录的频率也可以通过redis.conf文件配置**

![image-20230710112049176](https://picture-typora-zhangjingqi.oss-cn-beijing.aliyuncs.com/image-20230710112049176.png)

![image-20230710112318006](https://picture-typora-zhangjingqi.oss-cn-beijing.aliyuncs.com/image-20230710112318006.png)



**因为是记录命令，AOF文件会比RDB文件大的多**。

**而且AOF会记录对同一个key的多次写操作，但只有最后一次写操作才有意义**。

比如下面对num三次操作，其实只有最后一次对我们有用，前两次每用。

但是恢复数据的时候，前两句也要执行，不是很合理

```
set num 123
set num 456
set name jack 
set num 789
```

**通过执行bgrewriteaof命令，可以让AOF文件执行重写功能，用最少的命令达到相同效果**。

```
bgrewriteaof
```

![image-20230710114108159](https://picture-typora-zhangjingqi.oss-cn-beijing.aliyuncs.com/image-20230710114108159.png)

执行bgrewriteaof命令后，我们就可以把set num 123、set num 456两条命令抛弃，只记录set name jack 、set num 789两条命令，并且可以把最后两条命令进行合并，因为都是set命令

这样以后AOF的体积与之前相比小了很多

![image-20230710113759707](https://picture-typora-zhangjingqi.oss-cn-beijing.aliyuncs.com/image-20230710113759707.png)



**什么时候会执行bgrewriteaof命令，让文件执行重写功能呢？**

redis.conf中可以配置一个触发值，自动去重写AOF文件。

![image-20230710115853680](https://picture-typora-zhangjingqi.oss-cn-beijing.aliyuncs.com/image-20230710115853680.png)





## 1.3 RDB与AOF对比

![image-20230710140644400](https://picture-typora-zhangjingqi.oss-cn-beijing.aliyuncs.com/image-20230710140644400.png)

数据恢复优先级:RDB与AOF均使用，同时有这两个文件，Redis在启动时会以谁优先？那当然是AOF，文件数据更完整



# 二、Redis主从集群

## 2.1 介绍

**为什么需要主从架构**？

单节点Redis的并发能力是有上限的，要进一步提高Redis的并发能力，就需要搭建主从集群，实现读写分离

**为什么要做成主从集群而不是负载均衡集群？**

Redis应用中大多数是读多写少的场景。写操作我们在Master节点上操作，读操作在其他slave节点上操作

![image-20230710141645740](https://picture-typora-zhangjingqi.oss-cn-beijing.aliyuncs.com/image-20230710141645740.png)





## 2.2 搭建主从集群

> 来源黑马程序员

### 2.2.1 准备实例、配置

准备三个节点，一个主节点，两个从节点

![image-20230710144123513](https://picture-typora-zhangjingqi.oss-cn-beijing.aliyuncs.com/image-20230710144123513.png)



* **创建目录**

我们创建三个文件夹，名字分别叫7001、7002、7003：

```sh
# 进入/tmp目录
cd /tmp
# 创建目录
mkdir 7001 7002 7003
```

要在同一台虚拟机开启3个实例，必须准备三份不同的配置文件和目录，配置文件所在目录也就是工作目录。

* **恢复原始配置**

修改之前redis.conf文件，将其中的持久化模式改为默认的RDB模式，AOF保持关闭状态

* **拷贝配置文件到每个实例目录**

拷贝配置文件到三个目录中,可以使用下面的命令：

```sh
#万式一: 逐个烤贝
cp redis-6.2.4/redis.conf 7001
cp redis-6.2.4/redis.conf 7002
cp redis-6.2.4/redis.conf 7003

#方式二:管道组合命令，一健烤贝
echo 7001 7002 7003 | xargs -t -n 1 cp redis-6.2.4/redis.conf
```

* **修改每个实例的端口、工作目录**

修改配置文件的端口，分别为7001,7002,7003，将rdb文件保存位置都修改为自己所在目录（在/tmp目录执行下列命令）

```sh
sed -i -e 's/6379/7001/g' -e 's/dir .\//dir \/tmp\/7001\//g' 7001/redis.conf
sed -i -e 's/6379/7002/g' -e 's/dir .\//dir \/tmp\/7002\//g' 7002/redis.conf
sed -i -e 's/6379/7003/g' -e 's/dir .\//dir \/tmp\/7003\//g' 7003/redis.conf
```

* **修改每个实例的声明IP**

虚拟机本身有多个IP，为了避免将来混乱，我们需要在redis.conf文件中指定每一个实例的绑定ip信息，格式如下：

```properties
# redis实例的声明 IP
replica-announce-ip 192.168.150.101
```

每个目录都要改，我们一键完成修改（在/tmp目录执行下列命令）：

```sh
# 逐一执行
sed -i '1a replica-announce-ip 192.168.150.101' 7001/redis.conf
sed -i '1a replica-announce-ip 192.168.150.101' 7002/redis.conf
sed -i '1a replica-announce-ip 192.168.150.101' 7003/redis.conf

# 或者一键修改
printf '%s\n' 7001 7002 7003 | xargs -I{} -t sed -i '1a replica-announce-ip 192.168.150.101' {}/redis.conf
```



### 2.2.2 启动

为了方便查看日志，我们打开3个ssh窗口，分别启动3个redis实例，启动命令：

```sh
# 第1个
redis-server 7001/redis.conf
# 第2个
redis-server 7002/redis.conf
# 第3个
redis-server 7003/redis.conf
```

![image-20230710150156626](https://picture-typora-zhangjingqi.oss-cn-beijing.aliyuncs.com/image-20230710150156626.png)



如果要一键停止，可以运行下面命令：

```sh
printf '%s\n' 7001 7002 7003 | xargs -I{} -t redis-cli -p {} shutdown
```



### 2.2.3 开启主从关系

现在三个实例还没有任何关系，要配置主从可以使用replicaof 或者slaveof（5.0以前）命令。

**有临时和永久两种模式**：

- **修改配置文件（永久生效）**

  - 在redis.conf中添加一行配置：```slaveof <masterip> <masterport>```

  > 指定master的ip和端口

- **使用redis-cli客户端连接到redis服务，执行slaveof命令（重启后失效）**：

  ```sh
  slaveof <masterip> <masterport>
  ```

<strong><font color='red'>注意</font></strong>：在5.0以后新增命令replicaof，与salveof效果一致。

**这里我们为了演示方便，使用方式二**。

通过redis-cli命令连接7002，执行下面命令：

```sh
# 连接 7002
redis-cli -p 7002
# 执行slaveof
slaveof 192.168.150.101 7001
```

通过redis-cli命令连接7003，执行下面命令：

```sh
# 连接 7003
redis-cli -p 7003
# 执行slaveof
slaveof 192.168.150.101 7001
```



然后连接 7001节点，查看集群状态：

```sh
# 连接 7001
redis-cli -p 7001
# 查看状态
info replication
```



**总结**

**假设有A、B两个Redis实例，如何让B作为A的slave结点**？

在B节点执行命令：slaveof A的IP A的port



### 2.2.4 测试

执行下列操作以测试：

- 利用redis-cli连接7001，执行```set num 123```

- 利用redis-cli连接7002，执行```get num```，再执行```set num 666```

- 利用redis-cli连接7003，执行```get num```，再执行```set num 666```

![image-20230710151550501](https://picture-typora-zhangjingqi.oss-cn-beijing.aliyuncs.com/image-20230710151550501.png)

可以发现，只有在7001这个master节点上可以执行写操作，7002和7003这两个slave节点只能执行读操作。



## 2.3 数据同步原理

Redis的主从之间已经实现了这种数据的同步

主从第一次同步是**全量同步**

但如果slave重启后同步，则执行**增量同步**

### 2.3.1 全量同步

**第一阶段:判断一下是不是第一次**

**1.0**  salve与master第一次建立连接的时候需要执行一个slaveof命令或replicaof命令，并且指定master的ip和端口，这个过程就是slave与master建立连接的过程

**1.1**  连接一旦建立，sleep就可以向master发送请求了，“你的数据给我一份”，目的是确保数据的一致性。

**1.2**此时master接收到请求后，master就做一个判断，判断slave是不是第一次请求

**1.3**如果是第一次请求同步数据的话，master向slave返回master的数据版本信息

**1.4** slave接收到master的版本信息后，将其保存下来。将来可以基于数据版本做一个控制

![image-20230710155802791](https://picture-typora-zhangjingqi.oss-cn-beijing.aliyuncs.com/image-20230710155802930.png)

****

**第二阶段**

**2.1** master怎么把所有数据发给salve？之前学过bgsave命令。此时会执行bgsave命令，生成RDB，一旦生成，里面记录了完整的内存信息

**2.1.1**bgsave命令在执行过程中（异步的），主进程会处理其他的写操作，新写的数据并不会发送给slave，而是master将RDB这段时间内的命令记录到repl_baklog缓冲区中

> 也就是说RDB文件中的数据外 + repl_baklog缓冲区中的数据 = 完整数据

**2.2** master将RDB文件发送给slave

**2.3** slave接收文件后，将本地的数据清空，加载RDB文件。确保master与slave节点数据的基本一致

![image-20230710155813943](https://picture-typora-zhangjingqi.oss-cn-beijing.aliyuncs.com/image-20230710155813943.png)

****

**第三阶段**

**3.1** master发送repl_baklog中的命令到salve

**3.2**slave执行接收到的命令。此时保证master与slave节点数据完全一致

![image-20230710160036343](https://picture-typora-zhangjingqi.oss-cn-beijing.aliyuncs.com/image-20230710160036343.png)

**总流程图**

![image-20230710160401512](https://picture-typora-zhangjingqi.oss-cn-beijing.aliyuncs.com/image-20230710160401512.png)

****

**这种同步什么叫全量同步**？

因为有一个RDB的过程，会把内存形成快照整体发送给salve，这种同步是比较消耗性能的，生成RDB文件的速度比较慢

****

**master是怎么知道slave是第一次来呢？**

先看两个概念：

* **Replication ld**: 简称replid，是数据集的标记，id一致则说明是同一数据集。每一个master都有唯一的replid，slave则会继承master节点的replid

> slave第一次请求master的时候，master会把自己的id给slave，id一样，说明是同一个数据集

* **offset:偏移量**：随着记录在repl_baklog中的数据增多而逐渐增大。slave完成同步时也会记录当前同步的ofset。

  如果slave的offset小于master的offset，说明slave数据落后于master，需要更新。

> 也就是说offset越大,记录在repl_baklog里面的数据就越多

**因此slave做数据同步，必须向master声明自己的replication id 和offset，master才可以判断到底需要同步哪些数据**

**所以说了这么多，到底是怎么判断的？**

> offset>0，这么判断是不行的，因为不一定是从我们这个master同步过去的，也有可能从其他master同步的

**基于Replication ld判断，如果不一样，就说明是第一次来**

所以

**1.1** slave向master发送请求申请数据同步的时候，需要携带Replication ld与offset

**1.2**判断是否是第一次同步时，比对一下Replication ld是否一致即可，如果不一致拒绝增量同步，开启全量同步

![image-20230710161615054](https://picture-typora-zhangjingqi.oss-cn-beijing.aliyuncs.com/image-20230710161615054.png)





### 2.3.2 增量同步

主从第一次同步是**全量同步**

但如果slave重启后同步，则执行**增量同步**

****

**1.0 重启**

在slave重启的过程中，数据肯定会落后于master，此时就需要我们去做一次同步

**1.1** slave向master发送请求申请数据同步的时候，需要携带Replication ld与offset

**1.2**判断是否是第一次同步时，比对一下Replication ld是否一致即可，如果不一致拒绝增量同步，开启全量同步。

> 这个地方开启增量同步

**1.3**如果是第一次请求同步数据的话，master向slave返回master的数据版本信息；

如果不是第一次请求同步数据的话，恢复continue

> 下一步不用做RDB了，slave与master不同步的数据在repl_baklog中

![image-20230710162910903](https://picture-typora-zhangjingqi.oss-cn-beijing.aliyuncs.com/image-20230710162910903.png)

****

**2.1 **去repl_baklog中获取offset后的数据

**2.2 **master发送offset后的命令到slave

**2.3 **slave执行命令

![image-20230710162930396](https://picture-typora-zhangjingqi.oss-cn-beijing.aliyuncs.com/image-20230710162930396.png)

****

**offset是记录的repl_baklog缓冲区的哪一个部分呢？怎么找到之后的那些命令的呢？**

repl_baklog本质是一个数组。当数据记录满之后，会从0开始记录，把之前的数据覆盖掉（环型的一种记录方式）

![image-20230710163251875](https://picture-typora-zhangjingqi.oss-cn-beijing.aliyuncs.com/image-20230710163251875.png)

但是如果如果超过repl_baklog的存储上限的话（也就是红色把绿色覆盖后，slave跟不上master的进度了），那就没法做增量同步

如下图，slave宕机后无法做数据同步，master转了一圈追上slave，已经沾满了数组的空间。但是此时还不是最危险的

master还在记录新的命令，覆盖了一小部分绿色的，这还是正常的，没有什么危险

![image-20230710163545097](https://picture-typora-zhangjingqi.oss-cn-beijing.aliyuncs.com/image-20230710163545097.png)

下面是最危险的，已经出现问题了

master饶了一圈，到了自己的尾部，覆盖掉了一下slave还没有同步的命令

![image-20230710163803845](https://picture-typora-zhangjingqi.oss-cn-beijing.aliyuncs.com/image-20230710163803845.png)



repl_baklog大小有上限，写满后会覆盖最早的数据。

**如果slave断开时间过久，导致尚未备份的数据被覆盖”则无法基于log做增量同步，只能再次全量同步**。



### 2.3.3 主从同步优化

**总体思想**：减少全量同步，优化全量同步的性能

* **在master中配置repl-diskless-sync yes启用无磁盘复制，避免全量同步时的磁盘IO**

  正常的复制要生成RDB文件，我们就不生成了

  不把RDB文件写入到磁盘，而是写到网络当中，直接发送给slave，减少了一个磁盘读写

> 磁盘读取比较慢，但是网路特别快的时候使用

* **Redis单节点上的内存占用不要太大，减少RDB导致的过多磁盘I0**

* **适当提高repl_baklog的大小，发现slave宕机时尽快实现故障恢复，尽可能避免全量同步**
* **限制一个master上的slave节点数量，如果实在是太多slave，则可以采用主-从-从链式结构，减少master压力**

还有一个是主节点同步的压力问题，如果slave节点非常多，都去找slave节点去做数据同步，就会给主节点造成很大的压力

![image-20230710164817507](https://picture-typora-zhangjingqi.oss-cn-beijing.aliyuncs.com/image-20230710164817507.png)





## 2.4 总结

**全量同步和增量同步区别**

* 全量同步:master将完整内存数据生成RDB，发送RDB到slave。后续命令则记录在repl_baklog，逐个发送给slave。

* 增量同步: slave提交自己的offset到master，master获取repl_baklog中从offset之后的命令给slave

***

**什么时候执行全量同步?**

* slave节点第一次连接master节点时

* slave节点断开时间太久，repl baklog中的offset已经被覆盖时

***

**什么时候执行增量同步?**

* slave节点断开又恢复，并且在repl baklog中能找到offset时

***



#  三、哨兵模式

